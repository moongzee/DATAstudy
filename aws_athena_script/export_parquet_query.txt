1. CTAS 쿼리로 parquet 저장 

-- 기존 table 을 parquet 형식으로 변경해 원하는 S3 storage 지정하여 저장.

CREATE TABLE "{new_table_name}"
WITH (
      format = 'PARQUET',
      write_compression = 'SNAPPY',
      external_location = 's3://{bucket}/{object}')
AS 
SELECT *
FROM "{old_table_name}";

-- 이건 뭐지? 
CREATE EXTERNAL TABLE `athena_created_parquet_snappy_data`(
  `year` smallint,  
  `month` smallint,
  `day_of_month` smallint,
...
)
ROW FORMAT SERDE
  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS INPUTFORMAT
  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'
OUTPUTFORMAT
  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
LOCATION
  's3://{bucket}/{object}'
TBLPROPERTIES (
  'has_encrypted_data'='false',
  'parquet.compression'='SNAPPY');



2. UNLOAD 쿼리로 parquet 저장 

UNLOAD (SELECT * FROM "test"."tripdata1") 
TO 's3://sydev-lake/data/unload-export-to-parquet' 
WITH (format = 'PARQUET',compression = 'SNAPPY');